# ==============================================================================
# Deriva Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your values
# .env is gitignored for security

# ==============================================================================
# NEO4J CONFIGURATION
# ==============================================================================
# Neo4j connection (shared by graph_manager and archimate_manager)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j

# Neo4j connection pool settings
NEO4J_MAX_CONNECTION_LIFETIME=3600
NEO4J_MAX_CONNECTION_POOL_SIZE=50
NEO4J_CONNECTION_ACQUISITION_TIMEOUT=60
NEO4J_ENCRYPTED=false
NEO4J_TRUST=TRUST_ALL_CERTIFICATES

# Neo4j logging
NEO4J_LOG_LEVEL=INFO
NEO4J_LOG_QUERIES=false

# Manager namespaces (Neo4j label prefixes)
NEO4J_NAMESPACE_GRAPH=Graph
NEO4J_NAMESPACE_ARCHIMATE=Model

# ==============================================================================
# LLM CONFIGURATION
# ==============================================================================
# LLM Provider: azure, openai, anthropic, ollama
LLM_PROVIDER=azure

# Azure OpenAI settings
LLM_AZURE_API_URL=https://your-resource.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview
LLM_AZURE_API_KEY=your-api-key-here
LLM_AZURE_MODEL=gpt-4o-mini

# OpenAI settings (if using openai provider)
LLM_OPENAI_API_KEY=your-openai-key-here
LLM_OPENAI_MODEL=gpt-4o-mini

# Anthropic settings (if using anthropic provider)
LLM_ANTHROPIC_API_KEY=your-anthropic-key-here
LLM_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama settings (if using ollama provider - local LLM)
LLM_OLLAMA_API_URL=http://localhost:11434/api/chat
LLM_OLLAMA_MODEL=llama3.2

# LLM cache settings
LLM_CACHE_DIR=workspace/cache
LLM_CACHE_TTL=0
LLM_MAX_RETRIES=3
LLM_TIMEOUT=60
LLM_NOCACHE=false

# ==============================================================================
# BENCHMARKING - Multiple Model Configurations
# ==============================================================================
# Define multiple LLM models for benchmarking. Pattern:
#   LLM_BENCH_{NAME}_PROVIDER = azure | openai | anthropic | ollama
#   LLM_BENCH_{NAME}_MODEL = model identifier
#   LLM_BENCH_{NAME}_URL = API URL (optional, uses provider default)
#   LLM_BENCH_{NAME}_KEY = API key (optional)
#   LLM_BENCH_{NAME}_KEY_ENV = env var name for key (alternative to direct key)
#
# The NAME becomes the model identifier (e.g., AZURE_GPT4 -> azure-gpt4)

# Example: Azure GPT-4
# LLM_BENCH_AZURE_GPT4_PROVIDER=azure
# LLM_BENCH_AZURE_GPT4_MODEL=gpt-4
# LLM_BENCH_AZURE_GPT4_URL=https://your-resource.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview
# LLM_BENCH_AZURE_GPT4_KEY=your-azure-api-key

# Example: OpenAI GPT-4o
# LLM_BENCH_OPENAI_GPT4O_PROVIDER=openai
# LLM_BENCH_OPENAI_GPT4O_MODEL=gpt-4o
# LLM_BENCH_OPENAI_GPT4O_KEY=your-openai-api-key

# Example: Anthropic Claude
# LLM_BENCH_ANTHROPIC_SONNET_PROVIDER=anthropic
# LLM_BENCH_ANTHROPIC_SONNET_MODEL=claude-3-5-sonnet-20241022
# LLM_BENCH_ANTHROPIC_SONNET_KEY=your-anthropic-api-key

# Example: Local Ollama
# LLM_BENCH_OLLAMA_LLAMA_PROVIDER=ollama
# LLM_BENCH_OLLAMA_LLAMA_MODEL=llama3.2
# LLM_BENCH_OLLAMA_LLAMA_URL=http://localhost:11434/api/chat

# ==============================================================================
# DATABASE CONFIGURATION (DuckDB)
# ==============================================================================
# DuckDB database path (for config, file types, runs, etc.)
DATABASE_PATH=managers/database/sql.db

# ==============================================================================
# REPOSITORY MANAGER CONFIGURATION
# ==============================================================================
# Workspace directory for cloned repositories
REPOSITORY_WORKSPACE_DIR=workspace/repositories

# Repository defaults
REPOSITORY_DEFAULT_BRANCH=main
REPOSITORY_DEFAULT_CLONE_DEPTH=

# ==============================================================================
# GRAPH MANAGER CONFIGURATION
# ==============================================================================
# Graph manager namespace (should match NEO4J_NAMESPACE_GRAPH)
GRAPH_NAMESPACE=Graph

# Graph logging
GRAPH_LOG_LEVEL=INFO

# ==============================================================================
# ARCHIMATE MANAGER CONFIGURATION
# ==============================================================================
# ArchiMate manager namespace (should match NEO4J_NAMESPACE_ARCHIMATE)
ARCHIMATE_NAMESPACE=Model

# ArchiMate model settings
ARCHIMATE_VERSION=3.1
ARCHIMATE_IDENTIFIER_PREFIX=id-

# ArchiMate namespaces for XML export
ARCHIMATE_XML_NAMESPACE=http://www.opengroup.org/xsd/archimate/3.0/
ARCHIMATE_XML_DC_NAMESPACE=http://purl.org/dc/elements/1.1/
ARCHIMATE_XML_XSI_NAMESPACE=http://www.w3.org/2001/XMLSchema-instance

# Supported element types (comma-separated)
ARCHIMATE_ELEMENT_TYPES=ApplicationComponent,ApplicationInterface,ApplicationService,DataObject

# Supported relationship types (comma-separated)
ARCHIMATE_RELATIONSHIP_TYPES=Composition,Aggregation,Assignment,Realization,Serving,Access,Flow

# Validation settings
ARCHIMATE_VALIDATION_STRICT_MODE=false
ARCHIMATE_VALIDATION_ALLOW_CUSTOM_PROPERTIES=true

# Export settings
ARCHIMATE_EXPORT_PRETTY_PRINT=true
ARCHIMATE_EXPORT_ENCODING=UTF-8
ARCHIMATE_EXPORT_XML_DECLARATION=true
ARCHIMATE_EXPORT_VALIDATE_ON_EXPORT=true
ARCHIMATE_EXPORT_INCLUDE_METADATA=true

# ==============================================================================
# APPLICATION SETTINGS
# ==============================================================================
# Application environment: development, production
APP_ENV=development

# Logging
APP_LOG_LEVEL=INFO
APP_LOG_DIR=logs

# Output directory for generated ArchiMate files
OUTPUT_DIR=output
